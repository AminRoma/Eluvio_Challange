{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EluvioChallangeCode.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMRASbxpSqZgmOjCbNcPpE/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AminRoma/Eluvio_Challange/blob/main/EluvioChallangeCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_vxN54gAhhnH",
        "outputId": "4b4e3ebe-bac3-4aea-a7ac-2b31ae9c59b1"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import os\n",
        "import base64\n",
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.metrics import average_precision_score\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Nd_2hhNC_gNm"
      },
      "source": [
        "def calc_ap(gt_dict, pr_dict):\n",
        "    \"\"\"Average Precision (AP) for scene transitions.\n",
        "    Args:\n",
        "        gt_dict: Scene transition ground-truths.\n",
        "        pr_dict: Scene transition predictions.\n",
        "    Returns:\n",
        "        AP, mean AP, and a dict of AP for each movie.\n",
        "    \"\"\"\n",
        "    assert gt_dict.keys() == pr_dict.keys()\n",
        "\n",
        "    AP_dict = dict()\n",
        "    gt = list()\n",
        "    pr = list()\n",
        "    for imdb_id in gt_dict.keys():\n",
        "        AP_dict[imdb_id] = average_precision_score(gt_dict[imdb_id], pr_dict[imdb_id])\n",
        "        gt.append(gt_dict[imdb_id])\n",
        "        pr.append(pr_dict[imdb_id])\n",
        "\n",
        "    mAP = sum(AP_dict.values()) / len(AP_dict)\n",
        "\n",
        "    gt = np.concatenate(gt)\n",
        "    pr = np.concatenate(pr)\n",
        "    AP = average_precision_score(gt, pr)\n",
        "\n",
        "    return AP, mAP, AP_dict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p7kP59K1yOGB"
      },
      "source": [
        "def calc_miou(gt_dict, pr_dict, shot_to_end_frame_dict, threshold=0.5):\n",
        "    \"\"\"Maximum IoU (Miou) for scene segmentation.\n",
        "    Miou measures how well the predicted scenes and ground-truth scenes overlap. The descriptions can be found in\n",
        "    https://arxiv.org/pdf/1510.08893.pdf. Note the length of intersection or union is measured by the number of frames.\n",
        "    Args:\n",
        "        gt_dict: Scene transition ground-truths.\n",
        "        pr_dict: Scene transition predictions.\n",
        "        shot_to_end_frame_dict: End frame index for each shot.\n",
        "        threshold: A threshold to filter the predictions.\n",
        "    Returns:\n",
        "        Mean MIoU, and a dict of MIoU for each movie.\n",
        "    \"\"\"\n",
        "    def iou(x, y):\n",
        "        s0, e0 = x\n",
        "        s1, e1 = y\n",
        "        smin, smax = (s0, s1) if s1 > s0 else (s1, s0)\n",
        "        emin, emax = (e0, e1) if e1 > e0 else (e1, e0)\n",
        "        return (emin - smax + 1) / (emax - smin + 1)\n",
        "\n",
        "    def scene_frame_ranges(scene_transitions, shot_to_end_frame):\n",
        "        end_shots = np.where(scene_transitions)[0]\n",
        "        scenes = np.zeros((len(end_shots) + 1, 2), dtype=end_shots.dtype)\n",
        "        scenes[:-1, 1] = shot_to_end_frame[end_shots]\n",
        "        scenes[-1, 1] = shot_to_end_frame[len(scene_transitions)]\n",
        "        scenes[1:, 0] = scenes[:-1, 1] + 1\n",
        "        return scenes\n",
        "\n",
        "    def miou(gt_array, pr_array, shot_to_end_frame):\n",
        "        gt_scenes = scene_frame_ranges(gt_array, shot_to_end_frame)\n",
        "        pr_scenes = scene_frame_ranges(pr_array >= threshold, shot_to_end_frame)\n",
        "        assert gt_scenes[-1, -1] == pr_scenes[-1, -1]\n",
        "\n",
        "        m = gt_scenes.shape[0]\n",
        "        n = pr_scenes.shape[0]\n",
        "\n",
        "        # IoU for (gt_scene, pr_scene) pairs\n",
        "        iou_table = np.zeros((m, n))\n",
        "\n",
        "        j = 0\n",
        "        for i in range(m):\n",
        "            # j start prior to i end\n",
        "            while pr_scenes[j, 0] <= gt_scenes[i, 1]:\n",
        "                iou_table[i, j] = iou(gt_scenes[i], pr_scenes[j])\n",
        "                if j < n - 1:\n",
        "                    j += 1\n",
        "                else:\n",
        "                    break\n",
        "            # j end prior to (i + 1) start\n",
        "            if pr_scenes[j, 1] < gt_scenes[i, 1] + 1:\n",
        "                break\n",
        "            # j start later than (i + 1) start\n",
        "            if pr_scenes[j, 0] > gt_scenes[i, 1] + 1:\n",
        "                j -= 1\n",
        "        assert np.isnan(iou_table).sum() == 0\n",
        "        assert iou_table.min() >= 0\n",
        "\n",
        "        # Miou\n",
        "        return (iou_table.max(axis=0).mean() + iou_table.max(axis=1).mean()) / 2\n",
        "\n",
        "    assert gt_dict.keys() == pr_dict.keys()\n",
        "\n",
        "    miou_dict = dict()\n",
        "    for imdb_id in gt_dict.keys():\n",
        "         miou_dict[imdb_id] = miou(gt_dict[imdb_id], pr_dict[imdb_id], shot_to_end_frame_dict[imdb_id])\n",
        "    mean_miou = sum(miou_dict.values()) / len(miou_dict)\n",
        "\n",
        "    return mean_miou, miou_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b_eg2_kDyP_8"
      },
      "source": [
        "def calc_precision_recall(gt_dict, pr_dict, threshold=0.5):\n",
        "    \"\"\"Precision, Recall and F1 for scene transitions at a given threshold.\n",
        "    Args:\n",
        "        gt_dict: Scene transition ground-truths.\n",
        "        pr_dict: Scene transition predictions.\n",
        "        threshold: A threshold to filter the predictions.\n",
        "    Returns:\n",
        "        Mean Precision, Recall, and F1, per IMDB ID Precisions, Recalls, and F1 scores.\n",
        "    \"\"\"\n",
        "    def precision_recall(gt_array, pr_array):\n",
        "        tp_fn = gt_array == 1\n",
        "        tp_fp = pr_array >= threshold\n",
        "\n",
        "        tps = (tp_fn & tp_fp).sum()\n",
        "\n",
        "        precision = tps / tp_fp.sum()\n",
        "        recall = tps / tp_fn.sum()\n",
        "\n",
        "        return np.nan_to_num(precision), np.nan_to_num(recall)\n",
        "\n",
        "    assert gt_dict.keys() == pr_dict.keys()\n",
        "\n",
        "    precision_dict = dict()\n",
        "    recall_dict = dict()\n",
        "    fscore_dict = dict()\n",
        "\n",
        "    for imdb_id in gt_dict.keys():\n",
        "        p, r = precision_recall(gt_dict[imdb_id], pr_dict[imdb_id])\n",
        "        precision_dict[imdb_id] = p\n",
        "        recall_dict[imdb_id] = r\n",
        "        fscore_dict[imdb_id] = 2 * p * r / (p + r)\n",
        "\n",
        "    n = len(gt_dict)\n",
        "    mean_precision = sum(precision_dict.values()) / n\n",
        "    mean_recall = sum(recall_dict.values()) / n\n",
        "    mean_fscore = sum(fscore_dict.values()) / n\n",
        "\n",
        "    return mean_precision, mean_recall, mean_fscore, precision_dict, recall_dict, fscore_dict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llemTy6Cy4dS"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import json\n",
        "import pickle\n",
        "import os\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "#data_folder = os.path.join('https://github.com/AminRoma/Eluvio2')\n",
        "data_folder = os.path.join('/content/drive/MyDrive/Colab Notebooks/EluvioData/Eluvio')\n",
        "filenames = glob(os.path.join(data_folder, '*.pkl'))\n",
        "gt_dict = dict()\n",
        "pr_dict = dict()\n",
        "shot_to_end_frame_dict = dict()\n",
        "\n",
        "for fn in filenames:\n",
        "    x = pickle.load(open(fn, \"rb\"))\n",
        "\n",
        "    gt_dict[x[\"imdb_id\"]] = x[\"scene_transition_boundary_ground_truth\"]\n",
        "    pr_dict[x[\"imdb_id\"]] = x[\"scene_transition_boundary_prediction\"]\n",
        "    shot_to_end_frame_dict[x[\"imdb_id\"]] = x[\"shot_end_frame\"]\n",
        "\n",
        "    scores = dict()\n",
        "\n",
        "    #scores[\"AP\"], scores[\"mAP\"], _ = calc_ap(gt_dict, pr_dict)\n",
        "    #scores[\"Miou\"], _ = calc_miou(gt_dict, pr_dict, shot_to_end_frame_dict)\n",
        "    #scores[\"Precision\"], scores[\"Recall\"], scores[\"F1\"], *_ = calc_precision_recall(gt_dict, pr_dict)\n",
        "\n",
        "    p1 = pd.DataFrame(x['scene_transition_boundary_ground_truth']).astype(\"float\")  \n",
        "    p2 = pd.DataFrame(x['scene_transition_boundary_prediction']).astype(\"float\")  \n",
        "    p3 = pd.DataFrame(x['place']).astype(\"float\")  \n",
        "    p4 = pd.DataFrame(x['cast']).astype(\"float\")  \n",
        "    p5 = pd.DataFrame(x['action']).astype(\"float\")  \n",
        "    p6 = pd.DataFrame(x['audio']).astype(\"float\")\n",
        "\n",
        "\n",
        "    p = pd.concat([p3, p4,p5, p6, p1], axis=1, ignore_index=True)\n",
        "    p = p.head(-1)\n",
        "\n",
        "    X = p.iloc[ : , :-1].values\n",
        "    y = p.iloc [: , -1].values\n",
        "\n",
        "    imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
        "    imputer.fit(X[:, :])\n",
        "    X = imputer.transform(X[:, :])\n",
        "    sc = StandardScaler()\n",
        "    X[:,:] = sc.fit_transform(X[:,:])\n",
        "    kpca = KernelPCA(n_components=20, kernel = 'rbf')\n",
        "    X = kpca.fit_transform(X)\n",
        "    regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
        "  #  regressor = SVR(kernel ='rbf')\n",
        "    regressor.fit(X, y)\n",
        "    y_pred = regressor.predict(X)\n",
        "    y_pred = pd.DataFrame(y_pred)\n",
        "    with open('scene_transition_boundary_prediction.txt', 'w') as f:\n",
        "      sys.stdout = f # Change the standard output to the file we created.\n",
        "      print(y_pred)\n",
        "    #print(p)\n",
        "\n",
        "    pr_dict[x[\"imdb_id\"]] = y_pred \n",
        "    scores[\"AP\"], scores[\"mAP\"], _ = calc_ap(gt_dict, pr_dict)\n",
        "    scores[\"Miou\"], _ = calc_miou(gt_dict, pr_dict, shot_to_end_frame_dict)\n",
        "    #scores[\"Precision\"], scores[\"Recall\"], scores[\"F1\"], *_ = calc_precision_recall(gt_dict, pr_dict)\n",
        "    with open('ScoresRandomForrest.txt', 'w') as f:\n",
        "      sys.stdout = f # Change the standard output to the file we created.\n",
        "      print(scores[\"AP\"], scores[\"mAP\"], scores[\"Miou\"])\n",
        "    #sys.stdout = original_stdout # Reset the standard output to its original value\n",
        "   \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}